{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f22117-fe27-469e-80fd-78fa8775f5a7",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df083a1f-d106-4b79-88db-6e665585eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import (cross_val_score, StratifiedKFold)\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D, LeakyReLU)\n",
    "from tensorflow.keras.optimizers import (Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from math import floor\n",
    "from numpy import unique, reshape\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996e023-0bea-489e-b958-8480a9683f3b",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9a4f62d-52aa-44ed-9d2f-c7275aa58577",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\thoma\\OneDrive\\Dokumente\\data analytics\\ML_Ach\\ClimateWins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dec7b1c6-f104-4432-baa5-6c891ff36cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\thoma\\\\OneDrive\\\\Dokumente\\\\data analytics\\\\ML_Ach\\\\ClimateWins'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9befef30-dafe-48d7-bbfe-08aead484f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weather2 = pd.read_csv(os.path.join(path, 'Data', 'Prepared Data', 'Weather_unsc_clean.csv'))\n",
    "Pleasant_weather = pd.read_pickle(os.path.join(path, 'Data', 'Prepared Data', 'Pleasant_weather.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c2691a3-c36b-4ea3-ad1b-b788cb6cb927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 136)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weather2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e217d74d-e44c-4296-ba8c-49bfec169676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'Unnamed: 0' column\n",
    "Weather2 = Weather2.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a660e251-77b3-4539-b700-075389ed554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weather2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb23c720-6a4b-4d93-a8f2-31b7298b923e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BASEL_cloud_cover', 'BASEL_humidity', 'BASEL_pressure',\n",
       "       'BASEL_global_radiation', 'BASEL_precipitation', 'BASEL_sunshine',\n",
       "       'BASEL_temp_mean', 'BASEL_temp_min', 'BASEL_temp_max',\n",
       "       'BELGRADE_cloud_cover',\n",
       "       ...\n",
       "       'VALENTIA_pressure', 'VALENTIA_global_radiation',\n",
       "       'VALENTIA_precipitation', 'VALENTIA_sunshine', 'VALENTIA_temp_mean',\n",
       "       'VALENTIA_temp_min', 'VALENTIA_temp_max', 'KASSEL_cloud_cover',\n",
       "       'MUNCHENB_pressure', 'STOCKHOLM_humidity'],\n",
       "      dtype='object', length=135)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weather2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f78a329-4ca8-4e43-8cdd-cde745045c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_cols = Weather2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63e6e88f-6b6e-44cd-a151-7e12d58d16dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ['BASEL', 'BELGRADE', 'BUDAPEST', 'DEBILT', 'DUSSELDORF', 'HEATHROW', 'KASSEL', 'LJUBLJANA', 'MAASTRICHT', 'MADRID', 'MUNCHENB', 'OSLO', 'SONNBLICK', 'STOCKHOLM', 'VALENTIA']\n"
     ]
    }
   ],
   "source": [
    "col_info = (pd.Series(station_cols).str.split('_', n=1, expand=True).rename(columns={0: 'station', 1: 'obs'}))\n",
    "\n",
    "station_order = sorted(col_info['station'].unique())\n",
    "print(len(station_order), station_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd263912-dad5-456f-8224-8c563ac6c15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a NumPy array for X\n",
    "X = Weather2.to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15941e4f-0716-498a-b0c1-e3731412cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping\n",
    "X = X.reshape(-1, 15, 9)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a94f09a-fada-43fc-8c94-62637a901aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a NumPy array for y\n",
    "y = Pleasant_weather.to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00bef181-de63-4dae-a0f2-c29c69fc1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using argmax to get rid of one-hot encoding\n",
    "y = np.argmax(y, axis = 1)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2c412fea-8d0d-473e-bb4f-a4d236b23b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data, while preserving the temporal aspect/dependancy by 'not shuffling'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1cd0917c-4fe4-4a9f-ba36-e699335dfae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f22da-c9dd-45c3-95fb-ff6a7a026bb5",
   "metadata": {},
   "source": [
    "# BAYESIAN SEARCH OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3ffdf44-833e-4b8f-a7a9-4b698814b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "n_classes = int(y_train.max() + 1)\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "493744a3-15d2-4ff8-82f2-f1021fc96085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "                 'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "                 'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "                 'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential']\n",
    "\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    if np.isnan(score) or np.isinf(score):\n",
    "        return -1e10\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0bd300b9-f79a-419a-bbf5-49e84139ae8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  neurons  |  kernel   | activa... | optimizer | learni... | batch_... |  epochs   |  layers1  |  layers2  | normal... |  dropout  | dropou... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/17\n",
      "157/157 - 5s - 31ms/step - accuracy: 0.6893 - loss: 1.0001\n",
      "Epoch 2/17\n",
      "157/157 - 1s - 8ms/step - accuracy: 0.7422 - loss: 0.7487\n",
      "Epoch 3/17\n",
      "157/157 - 1s - 8ms/step - accuracy: 0.7618 - loss: 0.6867\n",
      "Epoch 4/17\n",
      "157/157 - 1s - 8ms/step - accuracy: 0.7676 - loss: 0.6520\n",
      "Epoch 5/17\n",
      "157/157 - 1s - 8ms/step - accuracy: 0.7742 - loss: 0.6261\n",
      "Epoch 6/17\n",
      "157/157 - 1s - 8ms/step - accuracy: 0.7783 - loss: 0.6077\n",
      "Epoch 7/17\n",
      "157/157 - 2s - 15ms/step - accuracy: 0.7852 - loss: 0.5898\n",
      "Epoch 8/17\n",
      "157/157 - 2s - 10ms/step - accuracy: 0.7927 - loss: 0.5775\n",
      "Epoch 9/17\n",
      "157/157 - 1s - 6ms/step - accuracy: 0.7961 - loss: 0.5649\n",
      "Epoch 10/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8018 - loss: 0.5472\n",
      "Epoch 11/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8029 - loss: 0.5334\n",
      "Epoch 12/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8100 - loss: 0.5221\n",
      "Epoch 13/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8133 - loss: 0.5100\n",
      "Epoch 14/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8188 - loss: 0.4933\n",
      "Epoch 15/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8213 - loss: 0.4807\n",
      "Epoch 16/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8242 - loss: 0.4753\n",
      "Epoch 17/17\n",
      "157/157 - 1s - 5ms/step - accuracy: 0.8345 - loss: 0.4528\n",
      "79/79 - 1s - 7ms/step\n",
      "Epoch 1/17\n",
      "Epoch 1/17\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m30.691915\u001b[39m | \u001b[39m2.8939252\u001b[39m | \u001b[39m5.3582183\u001b[39m | \u001b[39m1.9767709\u001b[39m | \u001b[39m0.0022883\u001b[39m | \u001b[39m78.035545\u001b[39m | \u001b[39m16.685568\u001b[39m | \u001b[39m1.7848849\u001b[39m | \u001b[39m2.2361046\u001b[39m | \u001b[39m0.4119300\u001b[39m | \u001b[39m0.0024648\u001b[39m | \u001b[39m0.2652096\u001b[39m |\n",
      "Epoch 1/22\n",
      "350/350 - 7s - 19ms/step - accuracy: 0.6415 - loss: 1.6278\n",
      "Epoch 2/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1827\n",
      "Epoch 3/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1723\n",
      "Epoch 4/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1692\n",
      "Epoch 5/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1670\n",
      "Epoch 6/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1665\n",
      "Epoch 7/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1661\n",
      "Epoch 8/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1656\n",
      "Epoch 9/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1655\n",
      "Epoch 10/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1654\n",
      "Epoch 11/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1652\n",
      "Epoch 12/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1652\n",
      "Epoch 13/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1652\n",
      "Epoch 14/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1652\n",
      "Epoch 15/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1651\n",
      "Epoch 16/22\n",
      "350/350 - 2s - 6ms/step - accuracy: 0.6431 - loss: 1.1650\n",
      "Epoch 17/22\n",
      "350/350 - 2s - 6ms/step - accuracy: 0.6431 - loss: 1.1650\n",
      "Epoch 18/22\n",
      "350/350 - 2s - 6ms/step - accuracy: 0.6431 - loss: 1.1651\n",
      "Epoch 19/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 20/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 21/22\n",
      "350/350 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 22/22\n",
      "350/350 - 2s - 6ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "175/175 - 1s - 4ms/step\n",
      "Epoch 1/22\n",
      "Epoch 1/22\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m45.397901\u001b[39m | \u001b[39m1.6008193\u001b[39m | \u001b[39m4.1270730\u001b[39m | \u001b[39m6.8489884\u001b[39m | \u001b[39m0.0084664\u001b[39m | \u001b[39m34.555280\u001b[39m | \u001b[39m21.789778\u001b[39m | \u001b[39m1.5758688\u001b[39m | \u001b[39m2.6449326\u001b[39m | \u001b[39m0.6261830\u001b[39m | \u001b[39m0.1104777\u001b[39m | \u001b[39m0.0001586\u001b[39m |\n",
      "Epoch 1/43\n",
      "204/204 - 3s - 17ms/step - accuracy: 0.6798 - loss: 0.9284\n",
      "Epoch 2/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.7286 - loss: 0.7640\n",
      "Epoch 3/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.7564 - loss: 0.6851\n",
      "Epoch 4/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.7806 - loss: 0.6286\n",
      "Epoch 5/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.7932 - loss: 0.5847\n",
      "Epoch 6/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8092 - loss: 0.5629\n",
      "Epoch 7/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8176 - loss: 0.5269\n",
      "Epoch 8/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8171 - loss: 0.5127\n",
      "Epoch 9/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8287 - loss: 0.5025\n",
      "Epoch 10/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8350 - loss: 0.4758\n",
      "Epoch 11/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8425 - loss: 0.4576\n",
      "Epoch 12/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8464 - loss: 0.4484\n",
      "Epoch 13/43\n",
      "204/204 - 1s - 7ms/step - accuracy: 0.8494 - loss: 0.4369\n",
      "Epoch 14/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8534 - loss: 0.4248\n",
      "Epoch 15/43\n",
      "204/204 - 1s - 7ms/step - accuracy: 0.8554 - loss: 0.4269\n",
      "Epoch 16/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8598 - loss: 0.4047\n",
      "Epoch 17/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8593 - loss: 0.4079\n",
      "Epoch 18/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8615 - loss: 0.4002\n",
      "Epoch 19/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8675 - loss: 0.3902\n",
      "Epoch 20/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8712 - loss: 0.3848\n",
      "Epoch 21/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8696 - loss: 0.3768\n",
      "Epoch 22/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8692 - loss: 0.3800\n",
      "Epoch 23/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8765 - loss: 0.3596\n",
      "Epoch 24/43\n",
      "204/204 - 1s - 7ms/step - accuracy: 0.8756 - loss: 0.3629\n",
      "Epoch 25/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8786 - loss: 0.3506\n",
      "Epoch 26/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8799 - loss: 0.3581\n",
      "Epoch 27/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8791 - loss: 0.3586\n",
      "Epoch 28/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8833 - loss: 0.3448\n",
      "Epoch 29/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8828 - loss: 0.3401\n",
      "Epoch 30/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8868 - loss: 0.3318\n",
      "Epoch 31/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8843 - loss: 0.3397\n",
      "Epoch 32/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8896 - loss: 0.3337\n",
      "Epoch 33/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8897 - loss: 0.3339\n",
      "Epoch 34/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8945 - loss: 0.3155\n",
      "Epoch 35/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8889 - loss: 0.3248\n",
      "Epoch 36/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8913 - loss: 0.3165\n",
      "Epoch 37/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8926 - loss: 0.3265\n",
      "Epoch 38/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8975 - loss: 0.3019\n",
      "Epoch 39/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8962 - loss: 0.3058\n",
      "Epoch 40/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.8978 - loss: 0.2965\n",
      "Epoch 41/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.9007 - loss: 0.2961\n",
      "Epoch 42/43\n",
      "204/204 - 1s - 5ms/step - accuracy: 0.9003 - loss: 0.2998\n",
      "Epoch 43/43\n",
      "204/204 - 1s - 6ms/step - accuracy: 0.8975 - loss: 0.3082\n",
      "102/102 - 0s - 4ms/step\n",
      "Epoch 1/43\n",
      "Epoch 1/43\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m47.686649\u001b[39m | \u001b[39m1.2830015\u001b[39m | \u001b[39m2.9511756\u001b[39m | \u001b[39m2.4254260\u001b[39m | \u001b[39m0.0087108\u001b[39m | \u001b[39m60.002126\u001b[39m | \u001b[39m43.150059\u001b[39m | \u001b[39m2.4357036\u001b[39m | \u001b[39m1.2384533\u001b[39m | \u001b[39m0.5963841\u001b[39m | \u001b[39m0.1297562\u001b[39m | \u001b[39m0.0232602\u001b[39m |\n",
      "Epoch 1/36\n",
      "146/146 - 2s - 17ms/step - accuracy: 0.6292 - loss: 1.2749\n",
      "Epoch 2/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1714\n",
      "Epoch 3/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1692\n",
      "Epoch 4/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1680\n",
      "Epoch 5/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1667\n",
      "Epoch 6/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1664\n",
      "Epoch 7/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1660\n",
      "Epoch 8/36\n",
      "146/146 - 1s - 8ms/step - accuracy: 0.6431 - loss: 1.1654\n",
      "Epoch 9/36\n",
      "146/146 - 1s - 7ms/step - accuracy: 0.6431 - loss: 1.1642\n",
      "Epoch 10/36\n",
      "146/146 - 2s - 10ms/step - accuracy: 0.6431 - loss: 1.1649\n",
      "Epoch 11/36\n",
      "146/146 - 2s - 12ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 12/36\n",
      "146/146 - 1s - 10ms/step - accuracy: 0.6431 - loss: 1.1630\n",
      "Epoch 13/36\n",
      "146/146 - 1s - 8ms/step - accuracy: 0.6431 - loss: 1.1625\n",
      "Epoch 14/36\n",
      "146/146 - 1s - 7ms/step - accuracy: 0.6431 - loss: 1.1625\n",
      "Epoch 15/36\n",
      "146/146 - 1s - 7ms/step - accuracy: 0.6431 - loss: 1.1624\n",
      "Epoch 16/36\n",
      "146/146 - 1s - 8ms/step - accuracy: 0.6431 - loss: 1.1622\n",
      "Epoch 17/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1615\n",
      "Epoch 18/36\n",
      "146/146 - 1s - 8ms/step - accuracy: 0.6431 - loss: 1.1607\n",
      "Epoch 19/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1608\n",
      "Epoch 20/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1608\n",
      "Epoch 21/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1593\n",
      "Epoch 22/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1593\n",
      "Epoch 23/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1595\n",
      "Epoch 24/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1586\n",
      "Epoch 25/36\n",
      "146/146 - 1s - 7ms/step - accuracy: 0.6431 - loss: 1.1578\n",
      "Epoch 26/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1568\n",
      "Epoch 27/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1568\n",
      "Epoch 28/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1560\n",
      "Epoch 29/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1558\n",
      "Epoch 30/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1542\n",
      "Epoch 31/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1539\n",
      "Epoch 32/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1542\n",
      "Epoch 33/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1520\n",
      "Epoch 34/36\n",
      "146/146 - 1s - 6ms/step - accuracy: 0.6431 - loss: 1.1511\n",
      "Epoch 35/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1507\n",
      "Epoch 36/36\n",
      "146/146 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1499\n",
      "73/73 - 1s - 7ms/step\n",
      "Epoch 1/36\n",
      "Epoch 1/36\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m43.248210\u001b[39m | \u001b[39m1.9287712\u001b[39m | \u001b[39m1.1340873\u001b[39m | \u001b[39m3.8358270\u001b[39m | \u001b[39m0.0059260\u001b[39m | \u001b[39m84.152921\u001b[39m | \u001b[39m36.233818\u001b[39m | \u001b[39m2.1154135\u001b[39m | \u001b[39m1.3564945\u001b[39m | \u001b[39m0.2405835\u001b[39m | \u001b[39m0.5060546\u001b[39m | \u001b[39m0.1190237\u001b[39m |\n",
      "Epoch 1/19\n",
      "140/140 - 2s - 17ms/step - accuracy: 0.6757 - loss: 0.9931\n",
      "Epoch 2/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7229 - loss: 0.8227\n",
      "Epoch 3/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7369 - loss: 0.7713\n",
      "Epoch 4/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7467 - loss: 0.7397\n",
      "Epoch 5/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7565 - loss: 0.7157\n",
      "Epoch 6/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7625 - loss: 0.6988\n",
      "Epoch 7/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7654 - loss: 0.6836\n",
      "Epoch 8/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7670 - loss: 0.6704\n",
      "Epoch 9/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7712 - loss: 0.6605\n",
      "Epoch 10/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7754 - loss: 0.6519\n",
      "Epoch 11/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7750 - loss: 0.6464\n",
      "Epoch 12/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7784 - loss: 0.6367\n",
      "Epoch 13/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7785 - loss: 0.6315\n",
      "Epoch 14/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7824 - loss: 0.6245\n",
      "Epoch 15/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7819 - loss: 0.6227\n",
      "Epoch 16/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7841 - loss: 0.6166\n",
      "Epoch 17/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7853 - loss: 0.6105\n",
      "Epoch 18/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7889 - loss: 0.6062\n",
      "Epoch 19/19\n",
      "140/140 - 1s - 5ms/step - accuracy: 0.7888 - loss: 0.6019\n",
      "70/70 - 1s - 7ms/step\n",
      "Epoch 1/19\n",
      "Epoch 1/19\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m29.322207\u001b[39m | \u001b[39m2.9114796\u001b[39m | \u001b[39m6.3112153\u001b[39m | \u001b[39m3.5403152\u001b[39m | \u001b[39m0.0082249\u001b[39m | \u001b[39m87.940114\u001b[39m | \u001b[39m19.273333\u001b[39m | \u001b[39m1.1581109\u001b[39m | \u001b[39m1.9315258\u001b[39m | \u001b[39m0.8789758\u001b[39m | \u001b[39m0.1475030\u001b[39m | \u001b[39m0.0693753\u001b[39m |\n",
      "Epoch 1/20\n",
      "127/127 - 3s - 22ms/step - accuracy: 0.6437 - loss: 1.1465\n",
      "Epoch 2/20\n",
      "127/127 - 1s - 6ms/step - accuracy: 0.7080 - loss: 0.8290\n",
      "Epoch 3/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7292 - loss: 0.7544\n",
      "Epoch 4/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7416 - loss: 0.7123\n",
      "Epoch 5/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7600 - loss: 0.6746\n",
      "Epoch 6/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7658 - loss: 0.6447\n",
      "Epoch 7/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7743 - loss: 0.6237\n",
      "Epoch 8/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7900 - loss: 0.5953\n",
      "Epoch 9/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.7940 - loss: 0.5724\n",
      "Epoch 10/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8036 - loss: 0.5598\n",
      "Epoch 11/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8070 - loss: 0.5543\n",
      "Epoch 12/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8219 - loss: 0.5112\n",
      "Epoch 13/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8165 - loss: 0.5136\n",
      "Epoch 14/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8297 - loss: 0.4928\n",
      "Epoch 15/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8319 - loss: 0.4839\n",
      "Epoch 16/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8340 - loss: 0.4800\n",
      "Epoch 17/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8319 - loss: 0.4741\n",
      "Epoch 18/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8383 - loss: 0.4608\n",
      "Epoch 19/20\n",
      "127/127 - 1s - 7ms/step - accuracy: 0.8433 - loss: 0.4492\n",
      "Epoch 20/20\n",
      "127/127 - 1s - 8ms/step - accuracy: 0.8472 - loss: 0.4420\n",
      "64/64 - 1s - 8ms/step\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m46.717832\u001b[39m | \u001b[39m1.2581270\u001b[39m | \u001b[39m6.4148540\u001b[39m | \u001b[39m1.6435828\u001b[39m | \u001b[39m0.0061982\u001b[39m | \u001b[39m96.611143\u001b[39m | \u001b[39m20.205232\u001b[39m | \u001b[39m1.9005102\u001b[39m | \u001b[39m2.9450355\u001b[39m | \u001b[39m0.2393709\u001b[39m | \u001b[39m0.1986813\u001b[39m | \u001b[39m0.2063839\u001b[39m |\n",
      "Epoch 1/24\n",
      "360/360 - 4s - 11ms/step - accuracy: 0.6279 - loss: 1.3621\n",
      "Epoch 2/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1863\n",
      "Epoch 3/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1755\n",
      "Epoch 4/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1714\n",
      "Epoch 5/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1696\n",
      "Epoch 6/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1681\n",
      "Epoch 7/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1675\n",
      "Epoch 8/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1667\n",
      "Epoch 9/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1663\n",
      "Epoch 10/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1660\n",
      "Epoch 11/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1657\n",
      "Epoch 12/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1655\n",
      "Epoch 13/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1654\n",
      "Epoch 14/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1653\n",
      "Epoch 15/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1651\n",
      "Epoch 16/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1650\n",
      "Epoch 17/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1649\n",
      "Epoch 18/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1649\n",
      "Epoch 19/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 20/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 21/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 22/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 23/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 24/24\n",
      "360/360 - 2s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "180/180 - 1s - 4ms/step\n",
      "Epoch 1/24\n",
      "Epoch 1/24\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m43.800367\u001b[39m | \u001b[39m1.9066323\u001b[39m | \u001b[39m0.7095901\u001b[39m | \u001b[39m4.3599357\u001b[39m | \u001b[39m0.0009264\u001b[39m | \u001b[39m33.728696\u001b[39m | \u001b[39m23.819139\u001b[39m | \u001b[39m2.8109504\u001b[39m | \u001b[39m2.5972004\u001b[39m | \u001b[39m0.3842269\u001b[39m | \u001b[39m0.0927260\u001b[39m | \u001b[39m0.0380175\u001b[39m |\n",
      "Epoch 1/40\n",
      "170/170 - 4s - 21ms/step - accuracy: 0.7069 - loss: 0.8501\n",
      "Epoch 2/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7464 - loss: 0.7230\n",
      "Epoch 3/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7592 - loss: 0.6789\n",
      "Epoch 4/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7695 - loss: 0.6571\n",
      "Epoch 5/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7748 - loss: 0.6257\n",
      "Epoch 6/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7891 - loss: 0.5934\n",
      "Epoch 7/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7790 - loss: 0.6051\n",
      "Epoch 8/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7989 - loss: 0.5585\n",
      "Epoch 9/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8042 - loss: 0.5421\n",
      "Epoch 10/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8042 - loss: 0.5463\n",
      "Epoch 11/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.7970 - loss: 0.5604\n",
      "Epoch 12/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8132 - loss: 0.5178\n",
      "Epoch 13/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8123 - loss: 0.5146\n",
      "Epoch 14/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8165 - loss: 0.4986\n",
      "Epoch 15/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8149 - loss: 0.5025\n",
      "Epoch 16/40\n",
      "170/170 - 1s - 6ms/step - accuracy: 0.8210 - loss: 0.4766\n",
      "Epoch 17/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8271 - loss: 0.4660\n",
      "Epoch 18/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8280 - loss: 0.4668\n",
      "Epoch 19/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8377 - loss: 0.4498\n",
      "Epoch 20/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8402 - loss: 0.4405\n",
      "Epoch 21/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8441 - loss: 0.4214\n",
      "Epoch 22/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8502 - loss: 0.4312\n",
      "Epoch 23/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8630 - loss: 0.3945\n",
      "Epoch 24/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8570 - loss: 0.4067\n",
      "Epoch 25/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8569 - loss: 0.4051\n",
      "Epoch 26/40\n",
      "170/170 - 1s - 6ms/step - accuracy: 0.8641 - loss: 0.3899\n",
      "Epoch 27/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8391 - loss: 0.4351\n",
      "Epoch 28/40\n",
      "170/170 - 1s - 7ms/step - accuracy: 0.8669 - loss: 0.3921\n",
      "Epoch 29/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8730 - loss: 0.3718\n",
      "Epoch 30/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8768 - loss: 0.3496\n",
      "Epoch 31/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8883 - loss: 0.3266\n",
      "Epoch 32/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8828 - loss: 0.3392\n",
      "Epoch 33/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8761 - loss: 0.3574\n",
      "Epoch 34/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8840 - loss: 0.3412\n",
      "Epoch 35/40\n",
      "170/170 - 1s - 6ms/step - accuracy: 0.8848 - loss: 0.3407\n",
      "Epoch 36/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8874 - loss: 0.3247\n",
      "Epoch 37/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8841 - loss: 0.3444\n",
      "Epoch 38/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8790 - loss: 0.3525\n",
      "Epoch 39/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8870 - loss: 0.3251\n",
      "Epoch 40/40\n",
      "170/170 - 1s - 5ms/step - accuracy: 0.8876 - loss: 0.3195\n",
      "85/85 - 0s - 4ms/step\n",
      "Epoch 1/40\n",
      "Epoch 1/40\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m31.375891\u001b[39m | \u001b[39m2.0146083\u001b[39m | \u001b[39m3.5247434\u001b[39m | \u001b[39m0.8862474\u001b[39m | \u001b[39m0.0079337\u001b[39m | \u001b[39m71.723587\u001b[39m | \u001b[39m40.310774\u001b[39m | \u001b[39m1.9187281\u001b[39m | \u001b[39m1.1489184\u001b[39m | \u001b[39m0.6024878\u001b[39m | \u001b[39m0.4355991\u001b[39m | \u001b[39m0.0019284\u001b[39m |\n",
      "Epoch 1/20\n",
      "175/175 - 4s - 20ms/step - accuracy: 0.0087 - loss: 8.4124\n",
      "Epoch 2/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.0158 - loss: 7.2326\n",
      "Epoch 3/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.0287 - loss: 6.1444\n",
      "Epoch 4/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.0586 - loss: 5.1772\n",
      "Epoch 5/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.1065 - loss: 4.3571\n",
      "Epoch 6/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.1712 - loss: 3.7108\n",
      "Epoch 7/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.2348 - loss: 3.2287\n",
      "Epoch 8/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.2994 - loss: 2.8347\n",
      "Epoch 9/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.3515 - loss: 2.5435\n",
      "Epoch 10/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.3891 - loss: 2.3537\n",
      "Epoch 11/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.4205 - loss: 2.1959\n",
      "Epoch 12/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.4523 - loss: 2.0602\n",
      "Epoch 13/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.4690 - loss: 1.9441\n",
      "Epoch 14/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.4962 - loss: 1.8399\n",
      "Epoch 15/20\n",
      "175/175 - 1s - 5ms/step - accuracy: 0.5208 - loss: 1.7766\n",
      "Epoch 16/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.5269 - loss: 1.7332\n",
      "Epoch 17/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.5444 - loss: 1.6489\n",
      "Epoch 18/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.5574 - loss: 1.6259\n",
      "Epoch 19/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.5601 - loss: 1.5945\n",
      "Epoch 20/20\n",
      "175/175 - 1s - 4ms/step - accuracy: 0.5709 - loss: 1.5531\n",
      "88/88 - 0s - 5ms/step\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m11.865195\u001b[39m | \u001b[39m1.8374848\u001b[39m | \u001b[39m6.1478609\u001b[39m | \u001b[39m3.0311238\u001b[39m | \u001b[39m0.0064702\u001b[39m | \u001b[39m69.784484\u001b[39m | \u001b[39m19.607276\u001b[39m | \u001b[39m1.5914136\u001b[39m | \u001b[39m1.0100498\u001b[39m | \u001b[39m0.1288935\u001b[39m | \u001b[39m0.5291550\u001b[39m | \u001b[39m0.1942484\u001b[39m |\n",
      "Epoch 1/34\n",
      "186/186 - 4s - 23ms/step - accuracy: 0.6400 - loss: 2.1656\n",
      "Epoch 2/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.2481\n",
      "Epoch 3/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1902\n",
      "Epoch 4/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1786\n",
      "Epoch 5/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1734\n",
      "Epoch 6/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1707\n",
      "Epoch 7/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1690\n",
      "Epoch 8/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1678\n",
      "Epoch 9/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1672\n",
      "Epoch 10/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1666\n",
      "Epoch 11/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1663\n",
      "Epoch 12/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1659\n",
      "Epoch 13/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1656\n",
      "Epoch 14/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1655\n",
      "Epoch 15/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1654\n",
      "Epoch 16/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1654\n",
      "Epoch 17/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1652\n",
      "Epoch 18/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1651\n",
      "Epoch 19/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1651\n",
      "Epoch 20/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1650\n",
      "Epoch 21/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1649\n",
      "Epoch 22/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 23/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 24/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 25/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 26/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 27/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1648\n",
      "Epoch 28/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 29/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1647\n",
      "Epoch 30/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 31/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 32/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1645\n",
      "Epoch 33/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1646\n",
      "Epoch 34/34\n",
      "186/186 - 1s - 5ms/step - accuracy: 0.6431 - loss: 1.1645\n",
      "93/93 - 1s - 5ms/step\n",
      "Epoch 1/34\n",
      "Epoch 1/34\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m15.814478\u001b[39m | \u001b[39m2.3827785\u001b[39m | \u001b[39m4.2389563\u001b[39m | \u001b[39m6.7448134\u001b[39m | \u001b[39m0.0084442\u001b[39m | \u001b[39m66.282011\u001b[39m | \u001b[39m34.139008\u001b[39m | \u001b[39m1.1709915\u001b[39m | \u001b[39m2.9091088\u001b[39m | \u001b[39m0.8951009\u001b[39m | \u001b[39m0.5583471\u001b[39m | \u001b[39m0.0846049\u001b[39m |\n",
      "Epoch 1/49\n",
      "395/395 - 6s - 15ms/step - accuracy: 0.6890 - loss: 0.9449\n",
      "Epoch 2/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7268 - loss: 0.7898\n",
      "Epoch 3/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7400 - loss: 0.7525\n",
      "Epoch 4/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7417 - loss: 0.7229\n",
      "Epoch 5/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7523 - loss: 0.7081\n",
      "Epoch 6/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7501 - loss: 0.7065\n",
      "Epoch 7/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7605 - loss: 0.6785\n",
      "Epoch 8/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7633 - loss: 0.6609\n",
      "Epoch 9/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7688 - loss: 0.6515\n",
      "Epoch 10/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7813 - loss: 0.6315\n",
      "Epoch 11/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7790 - loss: 0.6303\n",
      "Epoch 12/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7849 - loss: 0.6093\n",
      "Epoch 13/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.7914 - loss: 0.5928\n",
      "Epoch 14/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8033 - loss: 0.5715\n",
      "Epoch 15/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8059 - loss: 0.5572\n",
      "Epoch 16/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8098 - loss: 0.5458\n",
      "Epoch 17/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8157 - loss: 0.5304\n",
      "Epoch 18/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8211 - loss: 0.5127\n",
      "Epoch 19/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8236 - loss: 0.5088\n",
      "Epoch 20/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8275 - loss: 0.4970\n",
      "Epoch 21/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8308 - loss: 0.4829\n",
      "Epoch 22/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8359 - loss: 0.4704\n",
      "Epoch 23/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8355 - loss: 0.4695\n",
      "Epoch 24/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8418 - loss: 0.4543\n",
      "Epoch 25/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8399 - loss: 0.4600\n",
      "Epoch 26/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8483 - loss: 0.4477\n",
      "Epoch 27/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8505 - loss: 0.4284\n",
      "Epoch 28/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8514 - loss: 0.4290\n",
      "Epoch 29/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8530 - loss: 0.4400\n",
      "Epoch 30/49\n",
      "395/395 - 2s - 5ms/step - accuracy: 0.8463 - loss: 0.4388\n",
      "Epoch 31/49\n",
      "395/395 - 2s - 5ms/step - accuracy: 0.8574 - loss: 0.4148\n",
      "Epoch 32/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8578 - loss: 0.4166\n",
      "Epoch 33/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8609 - loss: 0.4025\n",
      "Epoch 34/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8573 - loss: 0.4078\n",
      "Epoch 35/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8607 - loss: 0.4042\n",
      "Epoch 36/49\n",
      "395/395 - 2s - 5ms/step - accuracy: 0.8636 - loss: 0.3893\n",
      "Epoch 37/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8663 - loss: 0.3896\n",
      "Epoch 38/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8681 - loss: 0.3880\n",
      "Epoch 39/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8703 - loss: 0.3768\n",
      "Epoch 40/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8665 - loss: 0.3918\n",
      "Epoch 41/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8729 - loss: 0.3704\n",
      "Epoch 42/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8660 - loss: 0.3878\n",
      "Epoch 43/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8668 - loss: 0.3817\n",
      "Epoch 44/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8670 - loss: 0.3793\n",
      "Epoch 45/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8699 - loss: 0.3761\n",
      "Epoch 46/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8750 - loss: 0.3649\n",
      "Epoch 47/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8724 - loss: 0.3697\n",
      "Epoch 48/49\n",
      "395/395 - 2s - 4ms/step - accuracy: 0.8756 - loss: 0.3688\n",
      "Epoch 49/49\n",
      "395/395 - 2s - 5ms/step - accuracy: 0.8758 - loss: 0.3588\n",
      "198/198 - 1s - 5ms/step\n",
      "Epoch 1/49\n",
      "Epoch 1/49\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m10.620562\u001b[39m | \u001b[39m2.2367446\u001b[39m | \u001b[39m3.0749685\u001b[39m | \u001b[39m5.7755145\u001b[39m | \u001b[39m0.0091148\u001b[39m | \u001b[39m31.010649\u001b[39m | \u001b[39m48.622526\u001b[39m | \u001b[39m2.9782540\u001b[39m | \u001b[39m1.3099135\u001b[39m | \u001b[39m0.8956331\u001b[39m | \u001b[39m0.5819656\u001b[39m | \u001b[39m0.1033591\u001b[39m |\n",
      "Epoch 1/46\n",
      "124/124 - 4s - 31ms/step - accuracy: 0.0011 - loss: 2.6752\n",
      "Epoch 2/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.6562\n",
      "Epoch 3/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.6358\n",
      "Epoch 4/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.6139\n",
      "Epoch 5/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.5910\n",
      "Epoch 6/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.5668\n",
      "Epoch 7/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.5418\n",
      "Epoch 8/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.5159\n",
      "Epoch 9/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.4892\n",
      "Epoch 10/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.4621\n",
      "Epoch 11/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.4342\n",
      "Epoch 12/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.4059\n",
      "Epoch 13/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.3773\n",
      "Epoch 14/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.3484\n",
      "Epoch 15/46\n",
      "124/124 - 1s - 6ms/step - accuracy: 0.0011 - loss: 2.3193\n",
      "Epoch 16/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.2900\n",
      "Epoch 17/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.2606\n",
      "Epoch 18/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.2310\n",
      "Epoch 19/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.2014\n",
      "Epoch 20/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.1719\n",
      "Epoch 21/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.1425\n",
      "Epoch 22/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.1130\n",
      "Epoch 23/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.0837\n",
      "Epoch 24/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.0549\n",
      "Epoch 25/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0011 - loss: 2.0260\n",
      "Epoch 26/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0033 - loss: 1.9976\n",
      "Epoch 27/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.0449 - loss: 1.9695\n",
      "Epoch 28/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.2788 - loss: 1.9419\n",
      "Epoch 29/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.4984 - loss: 1.9147\n",
      "Epoch 30/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.5511 - loss: 1.8880\n",
      "Epoch 31/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.5721 - loss: 1.8617\n",
      "Epoch 32/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.5879 - loss: 1.8359\n",
      "Epoch 33/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.5997 - loss: 1.8108\n",
      "Epoch 34/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6079 - loss: 1.7860\n",
      "Epoch 35/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6160 - loss: 1.7620\n",
      "Epoch 36/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6208 - loss: 1.7386\n",
      "Epoch 37/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6252 - loss: 1.7158\n",
      "Epoch 38/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6288 - loss: 1.6935\n",
      "Epoch 39/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6317 - loss: 1.6719\n",
      "Epoch 40/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6338 - loss: 1.6510\n",
      "Epoch 41/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6363 - loss: 1.6308\n",
      "Epoch 42/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6379 - loss: 1.6112\n",
      "Epoch 43/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6382 - loss: 1.5925\n",
      "Epoch 44/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6399 - loss: 1.5744\n",
      "Epoch 45/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6407 - loss: 1.5571\n",
      "Epoch 46/46\n",
      "124/124 - 1s - 5ms/step - accuracy: 0.6417 - loss: 1.5404\n",
      "62/62 - 1s - 9ms/step\n",
      "Epoch 1/46\n",
      "Epoch 1/46\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m10.933237\u001b[39m | \u001b[39m1.0502776\u001b[39m | \u001b[39m2.3711569\u001b[39m | \u001b[39m3.3170183\u001b[39m | \u001b[39m0.0006595\u001b[39m | \u001b[39m99.464399\u001b[39m | \u001b[39m45.736548\u001b[39m | \u001b[39m2.9580650\u001b[39m | \u001b[39m1.4499673\u001b[39m | \u001b[39m0.9415337\u001b[39m | \u001b[39m0.4077358\u001b[39m | \u001b[39m0.0452560\u001b[39m |\n",
      "Epoch 1/10\n",
      "383/383 - 3s - 8ms/step - accuracy: 0.6811 - loss: 0.9857\n",
      "Epoch 2/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7209 - loss: 0.8224\n",
      "Epoch 3/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7403 - loss: 0.7635\n",
      "Epoch 4/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7462 - loss: 0.7333\n",
      "Epoch 5/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7569 - loss: 0.7119\n",
      "Epoch 6/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7618 - loss: 0.6987\n",
      "Epoch 7/10\n",
      "383/383 - 2s - 4ms/step - accuracy: 0.7648 - loss: 0.6833\n",
      "Epoch 8/10\n",
      "383/383 - 2s - 4ms/step - accuracy: 0.7668 - loss: 0.6734\n",
      "Epoch 9/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7694 - loss: 0.6672\n",
      "Epoch 10/10\n",
      "383/383 - 1s - 4ms/step - accuracy: 0.7732 - loss: 0.6502\n",
      "192/192 - 1s - 4ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-1.00e+10\u001b[39m | \u001b[39m10.786188\u001b[39m | \u001b[39m1.4330031\u001b[39m | \u001b[39m2.0400053\u001b[39m | \u001b[39m2.1069459\u001b[39m | \u001b[39m0.0033340\u001b[39m | \u001b[39m31.993359\u001b[39m | \u001b[39m10.393882\u001b[39m | \u001b[39m2.0004997\u001b[39m | \u001b[39m2.2455603\u001b[39m | \u001b[39m0.4321485\u001b[39m | \u001b[39m0.3987122\u001b[39m | \u001b[39m0.2663656\u001b[39m |\n",
      "=========================================================================================================================================================================\n",
      "Search took 8.067874590555826 minutes\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 50),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 7),\n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.0001, 0.01),\n",
    "    'batch_size': (30, 100),\n",
    "    'epochs':(10, 50),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Running Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=23)\n",
    "nn_opt.maximize(init_points=10, n_iter=3)\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e0d6c5e-3123-4c84-a37b-27a0f731a660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neurons': 31,\n",
       " 'kernel': 3,\n",
       " 'activation': 'selu',\n",
       " 'optimizer': <keras.src.optimizers.rmsprop.RMSprop at 0x1e43d4ad280>,\n",
       " 'learning_rate': 0.0022883490962903605,\n",
       " 'batch_size': 78,\n",
       " 'epochs': 17,\n",
       " 'layers1': 2,\n",
       " 'layers2': 2,\n",
       " 'normalization': False,\n",
       " 'dropout': False,\n",
       " 'dropout_rate': 0.26520965471163144}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for the best hyperparameters\n",
    "optimum = nn_opt.max[\"params\"]\n",
    "\n",
    "learning_rate = float(optimum[\"learning_rate\"])\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential']\n",
    "act_i = int(np.clip(round(optimum[\"activation\"]), 0, len(activationL)-1))\n",
    "optimum[\"activation\"] = activationL[act_i]\n",
    "\n",
    "optimum[\"batch_size\"] = int(round(optimum[\"batch_size\"]))\n",
    "optimum[\"epochs\"]     = int(round(optimum[\"epochs\"]))\n",
    "optimum[\"layers1\"]    = int(round(optimum[\"layers1\"]))\n",
    "optimum[\"layers2\"]    = int(round(optimum[\"layers2\"]))\n",
    "optimum[\"neurons\"]    = int(round(optimum[\"neurons\"]))\n",
    "optimum[\"kernel\"]     = int(round(optimum[\"kernel\"]))  # dont forget kernel\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "opt_i = int(np.clip(round(optimum[\"optimizer\"]), 0, len(optimizerL)-1))\n",
    "opt_name = optimizerL[opt_i]\n",
    "\n",
    "optimizerD = {\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate),\n",
    "}\n",
    "optimum[\"optimizer\"] = optimizerD[opt_name]\n",
    "\n",
    "# optional: make flags booleans and clip dropout_rate\n",
    "optimum[\"normalization\"] = optimum[\"normalization\"] > 0.5\n",
    "optimum[\"dropout\"] = optimum[\"dropout\"] > 0.5\n",
    "optimum[\"dropout_rate\"] = float(np.clip(optimum[\"dropout_rate\"], 0.0, 0.3))\n",
    "\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece6ab8-2e17-4709-8fb8-f2cb65f74614",
   "metadata": {},
   "source": [
    "# -> These are the best hyperparameters within this specific search configuration, with regards to:\n",
    "# The search space bounds\n",
    "# The number of Bayesian iterations (13 trials)\n",
    "# 3-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9de03d8-563d-4168-8e4e-49ac27d24f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_80\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_80\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span> \n",
       "\n",
       " dense_394 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> \n",
       "\n",
       " dense_395 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> \n",
       "\n",
       " dense_396 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> \n",
       "\n",
       " dense_397 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> \n",
       "\n",
       " max_pooling1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_398 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,805</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv1d_80 (\u001b[38;5;33mConv1D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m31\u001b[0m)                    \u001b[38;5;34m868\u001b[0m \n",
       "\n",
       " dense_394 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m31\u001b[0m)                    \u001b[38;5;34m992\u001b[0m \n",
       "\n",
       " dense_395 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m31\u001b[0m)                    \u001b[38;5;34m992\u001b[0m \n",
       "\n",
       " dense_396 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m31\u001b[0m)                    \u001b[38;5;34m992\u001b[0m \n",
       "\n",
       " dense_397 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m31\u001b[0m)                    \u001b[38;5;34m992\u001b[0m \n",
       "\n",
       " max_pooling1d_80 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m31\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_80 (\u001b[38;5;33mFlatten\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_398 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                      \u001b[38;5;34m2,805\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,641</span> (29.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,641\u001b[0m (29.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,641</span> (29.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,641\u001b[0m (29.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final model including the best hyperparameters\n",
    "neurons = 31\n",
    "kernel = 3\n",
    "activation = 'selu'\n",
    "learning_rate = 0.0022883490962903605\n",
    "batch_size = 78\n",
    "epochs = 17\n",
    "layers1 = 2\n",
    "layers2 = 2\n",
    "normalization = False\n",
    "dropout = False\n",
    "dropout_rate = 0.26520965471163144\n",
    "\n",
    "timesteps = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "n_classes = int(y_train.max() + 1)\n",
    "\n",
    "optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for _ in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout:\n",
    "    model.add(Dropout(dropout_rate, seed=123))\n",
    "\n",
    "for _ in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "58e0467d-260d-41f6-91a9-2b196e54793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "236/236 - 3s - 12ms/step - accuracy: 0.6996 - loss: 0.8991\n",
      "Epoch 2/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.7621 - loss: 0.6859\n",
      "Epoch 3/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.7768 - loss: 0.6288\n",
      "Epoch 4/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.7870 - loss: 0.5876\n",
      "Epoch 5/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.7949 - loss: 0.5705\n",
      "Epoch 6/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8083 - loss: 0.5409\n",
      "Epoch 7/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8159 - loss: 0.5185\n",
      "Epoch 8/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8276 - loss: 0.4897\n",
      "Epoch 9/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8304 - loss: 0.4705\n",
      "Epoch 10/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8391 - loss: 0.4504\n",
      "Epoch 11/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8469 - loss: 0.4352\n",
      "Epoch 12/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8496 - loss: 0.4204\n",
      "Epoch 13/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8541 - loss: 0.4089\n",
      "Epoch 14/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8626 - loss: 0.3882\n",
      "Epoch 15/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8676 - loss: 0.3784\n",
      "Epoch 16/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8709 - loss: 0.3659\n",
      "Epoch 17/17\n",
      "236/236 - 1s - 5ms/step - accuracy: 0.8751 - loss: 0.3556\n",
      "Opt_loss: 0.4447675347328186 Opt_accuracy: 0.8538126349449158\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Opt_loss:\", loss, \"Opt_accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139cb21-ece9-42c2-b939-5fa3afef4e62",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d76e32f-7648-4fe1-b76e-c787969bc304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4590, 15)\n"
     ]
    }
   ],
   "source": [
    "# Converting y_test to one-hot encoded for creating the confusion matrix\n",
    "ty = to_categorical(np.asarray(y_test).ravel(), num_classes=15)\n",
    "print(ty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56684e34-14be-47a2-9143-94a4a8692b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_pred_probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f519856-7ec5-4f98-98e5-dde3480d9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_onehot(y_true_onehot, y_pred_probs, class_names=None):\n",
    "    y_true = np.argmax(y_true_onehot, axis=1)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    if class_names is None:\n",
    "        return pd.crosstab(pd.Series(y_true, name=\"True\"),\n",
    "                           pd.Series(y_pred, name=\"Pred\"))\n",
    "    else:\n",
    "        true_names = pd.Series([class_names[i] for i in y_true], name=\"True\")\n",
    "        pred_names = pd.Series([class_names[i] for i in y_pred], name=\"Pred\")\n",
    "        cm = pd.crosstab(true_names, pred_names, rownames=[\"True\"], colnames=[\"Pred\"])\n",
    "        return cm.reindex(index=class_names, columns=class_names, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d19f027c-c3f7-4e5e-9cb3-9f6cf6bd7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  KASSEL  \\\n",
      "True                                                                          \n",
      "BASEL        2827        73         8       4           0         1       0   \n",
      "BELGRADE      204       697         6       1           0         0       0   \n",
      "BUDAPEST       25        28        87       2           0         0       0   \n",
      "DEBILT         21         9         9      34           1         0       0   \n",
      "DUSSELDORF     12         3         2       3           5         1       0   \n",
      "HEATHROW       20         7        10       4           1        21       0   \n",
      "KASSEL          1         0         0       0           0         0       0   \n",
      "LJUBLJANA      17         5         1       0           1         0       0   \n",
      "MAASTRICHT      4         1         0       0           1         0       0   \n",
      "MADRID         42        23        11       4           0         4       0   \n",
      "MUNCHENB        8         1         0       0           0         0       0   \n",
      "OSLO            1         0         0       0           0         0       0   \n",
      "SONNBLICK       0         0         0       0           0         0       0   \n",
      "STOCKHOLM       0         0         0       0           0         0       0   \n",
      "VALENTIA        0         0         0       0           0         0       0   \n",
      "\n",
      "Pred        LJUBLJANA  MAASTRICHT  MADRID  MUNCHENB  OSLO  SONNBLICK  \\\n",
      "True                                                                   \n",
      "BASEL              10           2      32         0     0          0   \n",
      "BELGRADE            0           0       1         0     0          0   \n",
      "BUDAPEST            1           0       1         0     0          0   \n",
      "DEBILT              0           0       0         0     0          0   \n",
      "DUSSELDORF          3           1       3         0     0          0   \n",
      "HEATHROW            2           0      20         0     0          0   \n",
      "KASSEL              0           0       0         0     0          0   \n",
      "LJUBLJANA          17           0       4         0     0          0   \n",
      "MAASTRICHT          0           2       1         0     0          0   \n",
      "MADRID              7           0     229         0     0          0   \n",
      "MUNCHENB            0           0       0         0     0          0   \n",
      "OSLO                0           0       1         0     0          0   \n",
      "SONNBLICK           0           0       0         0     0          0   \n",
      "STOCKHOLM           0           0       1         1     0          0   \n",
      "VALENTIA            0           0       0         0     0          0   \n",
      "\n",
      "Pred        STOCKHOLM  VALENTIA  \n",
      "True                             \n",
      "BASEL               0         0  \n",
      "BELGRADE            0         0  \n",
      "BUDAPEST            0         0  \n",
      "DEBILT              0         0  \n",
      "DUSSELDORF          0         0  \n",
      "HEATHROW            0         0  \n",
      "KASSEL              0         0  \n",
      "LJUBLJANA           0         0  \n",
      "MAASTRICHT          0         0  \n",
      "MADRID              0         0  \n",
      "MUNCHENB            0         0  \n",
      "OSLO                0         0  \n",
      "SONNBLICK           0         0  \n",
      "STOCKHOLM           0         0  \n",
      "VALENTIA            0         0  \n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix_onehot(ty, y_pred_probs, class_names=station_order)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a0ca870a-6ce4-4a44-b245-4c5de0c84fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Pred    0    1   2   3   4   5   7   8    9   10\n",
      "True                                            \n",
      "0     2827   73   8   4   0   1  10   2   32   0\n",
      "1      204  697   6   1   0   0   0   0    1   0\n",
      "2       25   28  87   2   0   0   1   0    1   0\n",
      "3       21    9   9  34   1   0   0   0    0   0\n",
      "4       12    3   2   3   5   1   3   1    3   0\n",
      "5       20    7  10   4   1  21   2   0   20   0\n",
      "6        1    0   0   0   0   0   0   0    0   0\n",
      "7       17    5   1   0   1   0  17   0    4   0\n",
      "8        4    1   0   0   1   0   0   2    1   0\n",
      "9       42   23  11   4   0   4   7   0  229   0\n",
      "10       8    1   0   0   0   0   0   0    0   0\n",
      "11       1    0   0   0   0   0   0   0    1   0\n",
      "13       0    0   0   0   0   0   0   0    1   1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(confusion_matrix_onehot(ty, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d41d9-9337-4983-ac8b-4f7e0627ed1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
